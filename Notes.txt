Paper:

MTTS-CAN is an improvement to DeepPhys. Network completely based on 2D CNNs therfore takes only 6ms per frame. 
Potentially could be used for real-time HR measurement.

Experimental Setup:

During data acquisition, a multi-imager semicircular array (a total of 9 synchronized, visible spectrum imagers)
centered on the imaged participant in a controlled light environment was used to record the participantâ€™s head 
motions during specific tasks.

Each participant was recorded six times with increasing head motion in each task.

The six recordings were repeated twice in front of two backgrounds.



Questions:

In data_generator.py:

Q1. What is frame depth?    
Ans. Frame depth is the window size (number of adjacent frames)

Q2. Do I need to store the frames of all videos in the same np array as was done in 
data_generator.py ?

Ans. I will need to find the video having the least number of frames, and make all videos have the same number of frames as 
the minimum. This needs to be done because in data_generator.py, the videos in each batch are stored in a single array.



Code (Given):

When running predict_vitals.py, the x-axis of graph obtained contains the number of frames. y-axis is wave amplitude
I think.

By looking at the code, I found out that the authors did preprocessing on the dataset outside the current code base. This included adding the 
video frames, labels (ground truth for each frame) and the frame normalization in a single matlab file for each video.

The files are then read using the h5py library.

In data_generator.py, all videos are assumed to be of the same length. This is done so that all videos can be saved in one ndarray for each batch.


Code (My Version):

Will work with only UBFC for now and if there's time, I'll use PURE.

Stored data (video frames and corresponding data in a hdf5 file for each subject)

Each frame has a corresponding label (ppg signal value). The last frame of the video was excluded as it did not have a 
succeeding frame for normalization.

The frames were resized to 36x36 pixels.

Batch size was reduced to 12

Removed extra dimension from labels in data_generator.py. I think this dimension was for the ECG data from the AFRL dataset.


TODO:

Go through all TODOs in the codebase.








