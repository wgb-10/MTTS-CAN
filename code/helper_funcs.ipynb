{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used to test helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import csv\n",
    "from glob import iglob\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference: https://realpython.com/storing-images-in-python/#reading-many-images (Accessed 18/03/2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_frame(frame, title):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.title(title)\n",
    "    plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_many_disk(num_images, imagesPath, gtPath):\n",
    "    images, labels = [], []\n",
    "\n",
    "\n",
    "     # For each frame\n",
    "    for imagePath in imagesPath:\n",
    "        \n",
    "        # Store each frame \n",
    "        # print(f'[INFO] Working on Image: {image}')\n",
    "\n",
    "        # Read and resize the image\n",
    "        # Reference: https://pillow.readthedocs.io/en/stable/reference/Image.html (Accessed 21/03/2022)\n",
    "\n",
    "        with Image.open(imagePath) as image:\n",
    "            image_resized = image.resize((36, 36))\n",
    "            images.append(np.array(image_resized))\n",
    "        \n",
    "        # print(f'[INFO] images list contains: {len(images)} elements  of type {type(images[0])}')\n",
    "\n",
    "    with open(gtPath, \"r\") as csvfile:\n",
    "        reader = csv.reader(\n",
    "            csvfile, delimiter=\",\"\n",
    "        )\n",
    "\n",
    "        for idx, row in enumerate(reader):\n",
    "            \n",
    "            # Skip the title row\n",
    "            if idx > 0:\n",
    "                \n",
    "                # Skip the ppg recording for the last frame as it doesn't have a successor for normalization. \n",
    "                # This frame will only be used to normalize the 2nd last frame.\n",
    "                if len(labels) < num_images - 1:        \n",
    "                    ppg = float(row[2])                 # row[2] is the column containing ppg signal (label)\n",
    "                    # print(f'[INFO] ppg: {ppg}')\n",
    "                    labels.append(ppg)  \n",
    "\n",
    "    # print(f'[INFO] labels list contains: {len(labels)} elements  of type {type(labels[0])}')\n",
    "\n",
    "    # List containing the images with normailzed frames added in the 3rd dimension\n",
    "    expanded_images = []\n",
    "\n",
    "    # Perform frame normalization using every two adjacent frames as (c(t + 1) - c(t))/(c(t) + c(t + 1))\n",
    "    # where c is the channel of the frame.\n",
    "    for idx, image in enumerate(images):\n",
    "        if idx < len(images) - 1:\n",
    "            for i in range(3):\n",
    "\n",
    "                # print(f'[INFO] Shape of Frame {idx}: {(images[idx][:, :, i]).shape}')\n",
    "\n",
    "                # Displaying the frame at channel i\n",
    "                # display_frame(images[idx][:, :, i], f'Frame {idx} Channel {i}')   \n",
    "\n",
    "                # Normalized frame calculated by the formula above\n",
    "                normalizedFrame = (images[idx + 1][:, :, i] - images[idx][:, :, i]\n",
    "                ) / (images[idx][:, :, i] + images[idx + 1][:, :, i])\n",
    "\n",
    "                # Displaying the normalized frame at channel i\n",
    "                # display_frame(normalizedFrame, f'Normalized Frame {idx} Channel {i}')\n",
    "\n",
    "                # print(f'[INFO] Shape of Normalized Frame {idx}: {normalizedFrame.shape}')\n",
    "\n",
    "                # Adding an extra dimension to the normalized frame to make it possible to append to original image\n",
    "                normalizedFrame = np.expand_dims(normalizedFrame, axis=2)\n",
    "\n",
    "                image = np.append(image, normalizedFrame, axis=2)\n",
    "            \n",
    "            #     print(f'shape of normalizedFrame: {normalizedFrame.shape}')\n",
    "            #     print(f'shape of image: {image.shape}')\n",
    "\n",
    "            # print(f'shape of image after going through each channel: {image.shape}')\n",
    "            \n",
    "            # Storing the expanded images \n",
    "            expanded_images.append(image)\n",
    "            # break\n",
    "\n",
    "\n",
    "    return np.array(expanded_images), np.array(labels)\n",
    "\n",
    "    # # Loop over all IDs and read each image in one by one\n",
    "    # for image_id in range(num_images):\n",
    "    #     images.append(np.array(Image.open(disk_dir / f\"{image_id}.png\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_many_hdf5(target_dir, subID, images, labels):\n",
    "    \"\"\" Stores an array of images to HDF5.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        target_dir:  path to the directory where the HDF5 file will be stored.\n",
    "        subID:       subject ID.\n",
    "        images       images array, (N, W, H, NC) to be stored (where N: number of images, W: width, H: height, NC: number of channels).\n",
    "        labels       labels array, (N, 1) to be stored\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        pathToTarget    path to the HDF5 file.\n",
    "    \"\"\"\n",
    "\n",
    "    pathToTarget = os.path.join(target_dir, f\"{subID}.h5\")\n",
    "\n",
    "    # Create a new HDF5 file\n",
    "    file = h5py.File(pathToTarget, \"w\")\n",
    "\n",
    "    # Create a dataset in the file\n",
    "    dataset = file.create_dataset(\n",
    "        \"images\", data=images\n",
    "    )\n",
    "    meta_set = file.create_dataset(\n",
    "        \"labels\", data=labels\n",
    "    )\n",
    "    file.close()\n",
    "    \n",
    "    return pathToTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_many_hdf5(file_path):\n",
    "    \"\"\" Reads image from HDF5.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        path   path to file\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        images       images array, (N, W, H, NC) to be stored (where N: number of images, W: width, H: height, NC: number of channels).\n",
    "        labels       labels array, (N, 1) to be stored\n",
    "    \"\"\"\n",
    "    images, labels = [], []\n",
    "\n",
    "    # Open the HDF5 file\n",
    "    file = h5py.File(file_path, \"r+\")\n",
    "\n",
    "    images = np.array(file[\"/images\"]).astype(\"float64\")\n",
    "    labels = np.array(file[\"/labels\"]).astype(\"float64\")\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\AppData\\Local\\Temp\\ipykernel_980\\201566283.py:54: RuntimeWarning: invalid value encountered in true_divide\n",
      "  normalizedFrame = (images[idx + 1][:, :, i] - images[idx][:, :, i]\n",
      "C:\\Users\\wesle\\AppData\\Local\\Temp\\ipykernel_980\\201566283.py:54: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  normalizedFrame = (images[idx + 1][:, :, i] - images[idx][:, :, i]\n"
     ]
    }
   ],
   "source": [
    "# Get iterator over different subjects\n",
    "imageDirs = iglob(\"D:\\\\OneDrive\\\\Documents\\\\rPPG-Projects\\\\Datasets-Preprocessed\\\\UBFC2\\\\DATASET_2\\\\[0-9]*\\\\subject[0-9]*\")\n",
    "\n",
    "# Lists that will contain the images, labels and the subject IDs\n",
    "images, labels, subjects = [], [], []\n",
    "\n",
    "# For each subject\n",
    "for idx, path_ in enumerate(imageDirs):\n",
    "    # print(f\"[INFO] Working in {path_}\")\n",
    "\n",
    "    if idx > 9:\n",
    "        break  # Testing only for first 10 subjects (for now)\n",
    "  \n",
    "    # Get the number of frames\n",
    "    num_images = len(os.listdir(path_))\n",
    "\n",
    "    # print(f'[INFO] Number of images: {num_images}')\n",
    "    \n",
    "    # Get the path to the frames\n",
    "    imagesPath = iglob(os.path.join(path_, \"*.png\"))\n",
    "\n",
    "    # Get subject number from path\n",
    "    subID = path_.split(\"\\\\\")[-1]\n",
    "\n",
    "    # Add the subject ID to subjects list\n",
    "    subjects.append(subID)\n",
    "\n",
    "    # Get the path to the csv file\n",
    "    gtPath = path_.replace(subID, r\"0\\phys.csv\")    \n",
    "\n",
    "    images, labels = read_many_disk(num_images, imagesPath, gtPath) \n",
    "\n",
    "     # Create a new directory for the hdf5 file of subject\n",
    "    hdf5_dir = Path(r'D:\\OneDrive\\Documents\\rPPG-Projects\\Datasets-Preprocessed\\hdf5\\UBFC2\\DATASET_2')\n",
    "    if not os.path.exists(hdf5_dir): \n",
    "        hdf5_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Store the images and labels at the target path\n",
    "    storedFilePath = store_many_hdf5(hdf5_dir, subID, images, labels)\n",
    "\n",
    "    # Reading the stored data for each subject\n",
    "    images_, labels_ = read_many_hdf5(storedFilePath)\n",
    "\n",
    "    # Checking if the read_image function works by comparing stored images and labels with the images and labels \n",
    "    # read from the file \n",
    "    assert(images.all()==images_.all())\n",
    "    assert(labels.all()==labels_.all())\n",
    "\n",
    "# print(f'shape of images: {np.shape(images)}, type: {type(images)}')\n",
    "# print(f'shape of labels: {np.sha  pe(labels)}, type: {type(labels)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "721881c4ebbfc4a48f73e756600484e3f3653201792f48d5e9f9bb135cb791ab"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
